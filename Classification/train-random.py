import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support
from sklearn.utils import resample
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“Œ 1. Charger le dataset depuis `dataset.xlsx`
# df = pd.read_excel("dataset.xlsx", engine="openpyxl")
df = pd.read_excel("D:/PFM/IA/Classification/libelles_categorises.xlsx", engine="openpyxl") 

# ğŸ“Œ 2. VÃ©rification des donnÃ©es chargÃ©es
print(df.head())  # Afficher les premiÃ¨res lignes pour vÃ©rifier

# ğŸ“Œ 3. RÃ©Ã©quilibrer les donnÃ©es pour Ã©viter les biais
max_size = df['categorie'].value_counts().max()
df_balanced = df.groupby('categorie', group_keys=False).apply(lambda x: x.sample(max_size, replace=True))

print(df_balanced['categorie'].value_counts())  # VÃ©rification du rÃ©Ã©quilibrage

# ğŸ“Œ 4. PrÃ©paration des donnÃ©es
X = df_balanced["description"]  # Les phrases
y = df_balanced["categorie"]  # Les catÃ©gories Ã  prÃ©dire

# ğŸ“Œ 5. Transformer les descriptions en vecteurs TF-IDF
vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 2))
X_transformed = vectorizer.fit_transform(X)

# ğŸ“Œ 6. SÃ©parer les donnÃ©es en jeu d'entraÃ®nement et de test (80% - 20%)
X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)

# ğŸ“Œ 7. VÃ©rification des classes prÃ©sentes dans le jeu de test
print("Classes prÃ©sentes dans le jeu d'entraÃ®nement :", set(y_train.unique()))
print("Classes prÃ©sentes dans le jeu de test :", set(y_test.unique()))

# ğŸ“Œ 8. Initialiser le modÃ¨le Random Forest avec des hyperparamÃ¨tres ajustÃ©s
clf = RandomForestClassifier(
    n_estimators=50,  # RÃ©duit le nombre d'arbres pour Ã©viter l'overfitting
    max_depth=5,  # Limite la complexitÃ© des arbres
    min_samples_split=2,  # EmpÃªche la sur-segmentation des arbres
    random_state=42
)

# ğŸ“Œ 9. EntraÃ®ner le modÃ¨le
clf.fit(X_train, y_train)

# ğŸ“Œ 10. Ã‰valuation du modÃ¨le
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ PrÃ©cision du modÃ¨le Random Forest : {accuracy:.2f}")



# ğŸ“Œ 12. PrÃ©cision, Rappel, F1-Score
precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')
print(f"ğŸ¯ PrÃ©cision (weighted): {precision:.2f}")
print(f"ğŸ¯ Rappel (weighted): {recall:.2f}")
print(f"ğŸ¯ F1-Score (weighted): {f1:.2f}")



# ğŸ“Œ 14. Sauvegarde du modÃ¨le et du vectorizer
joblib.dump(clf, "transaction_classifier_rf.pkl")  # Sauvegarde du modÃ¨le
joblib.dump(vectorizer, "vectorizer_rf.pkl")  # Sauvegarde du vectorizer

print("âœ… ModÃ¨le Random Forest entraÃ®nÃ© et sauvegardÃ© avec succÃ¨s !")
