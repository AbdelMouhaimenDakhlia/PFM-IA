import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support
from sklearn.preprocessing import LabelEncoder
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“Œ 1. Charger le dataset depuis `dataset.xlsx`
df = pd.read_excel("D:/PFM/IA/Classification/libelles_categorises.xlsx", engine="openpyxl")

# ğŸ“Œ 2. VÃ©rification des donnÃ©es chargÃ©es
print(df.head())  # Afficher les premiÃ¨res lignes pour vÃ©rifier

# ğŸ“Œ 3. RÃ©Ã©quilibrer les donnÃ©es pour Ã©viter les biais
max_size = df['categorie'].value_counts().max()
df_balanced = df.groupby('categorie', group_keys=False).apply(lambda x: x.sample(max_size, replace=True))
print(df_balanced['categorie'].value_counts())  # VÃ©rification du rÃ©Ã©quilibrage

# ğŸ“Œ 4. PrÃ©paration des donnÃ©es
X = df_balanced["description"]  # Les phrases
y = df_balanced["categorie"]  # Les catÃ©gories Ã  prÃ©dire

# ğŸ“Œ 5. Encoder les labels en entiers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# ğŸ“Œ 6. Transformer les descriptions en vecteurs TF-IDF
vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 2))
X_transformed = vectorizer.fit_transform(X)

# ğŸ“Œ 7. SÃ©parer les donnÃ©es en jeu d'entraÃ®nement et de test (80% - 20%)
X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_encoded, test_size=0.3, random_state=42)

# ğŸ“Œ 8. Initialiser le modÃ¨le XGBoost
clf_xgb = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    random_state=42
)

# ğŸ“Œ 9. EntraÃ®ner le modÃ¨le
clf_xgb.fit(X_train, y_train)

# ğŸ“Œ 10. Ã‰valuation du modÃ¨le
y_pred = clf_xgb.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ PrÃ©cision du modÃ¨le XGBoost : {accuracy:.2f}")

# ğŸ“Œ 11. PrÃ©cision, Rappel, F1-Score
precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')
print(f"ğŸ¯ PrÃ©cision (weighted): {precision:.2f}")
print(f"ğŸ¯ Rappel (weighted): {recall:.2f}")
print(f"ğŸ¯ F1-Score (weighted): {f1:.2f}")

# ğŸ“Œ 12. Matrice de confusion
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('PrÃ©dictions')
plt.ylabel('VÃ©ritÃ© terrain')
plt.title('Matrice de confusion - XGBoost')
plt.show()

# ğŸ“Œ 13. Sauvegarde du modÃ¨le et des transformations
joblib.dump(clf_xgb, "transaction_classifier_xgb.pkl")  # Sauvegarde du modÃ¨le
joblib.dump(vectorizer, "vectorizer_xgb.pkl")  # Sauvegarde du vectorizer
joblib.dump(label_encoder, "label_encoder.pkl")  # Sauvegarde du label encoder

print("âœ… ModÃ¨le XGBoost entraÃ®nÃ© et sauvegardÃ© avec succÃ¨s !")
